{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.read_csv('../preprocess/1125_all.csv')\n",
    "df = pd.DataFrame(data)\n",
    "df = df.dropna()\n",
    "# df.rename(columns={\"160\":\"target\"}, inplace=True)\n",
    "data = df.iloc[:, :-1]\n",
    "target = df['target']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 160, 15)           1020      \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 7)                 644       \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 8         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,672\n",
      "Trainable params: 1,672\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "K.clear_session()\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.LSTM(15, activation=\"tanh\", input_shape=(train_input.shape[1],1), return_sequences=True))\n",
    "model.add(keras.layers.LSTM(7, activation=\"tanh\", dropout=0.3))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "64/64 [==============================] - 5s 29ms/step - loss: 0.6303 - accuracy: 0.6495 - val_loss: 0.5634 - val_accuracy: 0.6713\n",
      "Epoch 2/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.5181 - accuracy: 0.7836 - val_loss: 0.4782 - val_accuracy: 0.8269\n",
      "Epoch 3/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.4619 - accuracy: 0.8244 - val_loss: 0.4231 - val_accuracy: 0.8457\n",
      "Epoch 4/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.4180 - accuracy: 0.8458 - val_loss: 0.4182 - val_accuracy: 0.8407\n",
      "Epoch 5/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.4043 - accuracy: 0.8502 - val_loss: 0.4257 - val_accuracy: 0.8356\n",
      "Epoch 6/10\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.3949 - accuracy: 0.8536 - val_loss: 0.4698 - val_accuracy: 0.8356\n",
      "Epoch 7/10\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.3880 - accuracy: 0.8577 - val_loss: 0.3712 - val_accuracy: 0.8570\n",
      "Epoch 8/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.3822 - accuracy: 0.8577 - val_loss: 0.3738 - val_accuracy: 0.8557\n",
      "Epoch 9/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.3779 - accuracy: 0.8593 - val_loss: 0.3644 - val_accuracy: 0.8595\n",
      "Epoch 10/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.3718 - accuracy: 0.8628 - val_loss: 0.3492 - val_accuracy: 0.8645\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.3492 - accuracy: 0.8645\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.3329 - accuracy: 0.8835\n",
      "Epoch 1/10\n",
      "64/64 [==============================] - 7s 28ms/step - loss: 0.3860 - accuracy: 0.8574 - val_loss: 0.3478 - val_accuracy: 0.8645\n",
      "Epoch 2/10\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.3672 - accuracy: 0.8618 - val_loss: 0.3900 - val_accuracy: 0.8532\n",
      "Epoch 3/10\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.3633 - accuracy: 0.8709 - val_loss: 0.3868 - val_accuracy: 0.8532\n",
      "Epoch 4/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.3620 - accuracy: 0.8709 - val_loss: 0.4149 - val_accuracy: 0.8407\n",
      "Epoch 5/10\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.3557 - accuracy: 0.8728 - val_loss: 0.3226 - val_accuracy: 0.8795\n",
      "Epoch 6/10\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.3539 - accuracy: 0.8712 - val_loss: 0.3381 - val_accuracy: 0.8695\n",
      "Epoch 7/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.3601 - accuracy: 0.8697 - val_loss: 0.4307 - val_accuracy: 0.8344\n",
      "Epoch 8/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.3579 - accuracy: 0.8719 - val_loss: 0.3380 - val_accuracy: 0.8683\n",
      "Epoch 9/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.3569 - accuracy: 0.8725 - val_loss: 0.3217 - val_accuracy: 0.8833\n",
      "Epoch 10/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.3531 - accuracy: 0.8693 - val_loss: 0.3282 - val_accuracy: 0.8821\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.3282 - accuracy: 0.8821\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.3375 - accuracy: 0.8745\n",
      "Epoch 1/10\n",
      "64/64 [==============================] - 5s 31ms/step - loss: 0.3597 - accuracy: 0.8675 - val_loss: 0.3758 - val_accuracy: 0.8595\n",
      "Epoch 2/10\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.3697 - accuracy: 0.8656 - val_loss: 0.3420 - val_accuracy: 0.8683\n",
      "Epoch 3/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.3581 - accuracy: 0.8719 - val_loss: 0.3813 - val_accuracy: 0.8444\n",
      "Epoch 4/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.3588 - accuracy: 0.8684 - val_loss: 0.3146 - val_accuracy: 0.8871\n",
      "Epoch 5/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.3512 - accuracy: 0.8703 - val_loss: 0.3386 - val_accuracy: 0.8683\n",
      "Epoch 6/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.3485 - accuracy: 0.8722 - val_loss: 0.3303 - val_accuracy: 0.8908\n",
      "Epoch 7/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.3507 - accuracy: 0.8706 - val_loss: 0.3173 - val_accuracy: 0.8770\n",
      "Epoch 8/10\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.3457 - accuracy: 0.8731 - val_loss: 0.3525 - val_accuracy: 0.8620\n",
      "Epoch 9/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.3421 - accuracy: 0.8756 - val_loss: 0.3125 - val_accuracy: 0.8821\n",
      "Epoch 10/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.3410 - accuracy: 0.8759 - val_loss: 0.3693 - val_accuracy: 0.8582\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.3693 - accuracy: 0.8582\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.3251 - accuracy: 0.8725\n",
      "Epoch 1/10\n",
      "64/64 [==============================] - 5s 29ms/step - loss: 0.3446 - accuracy: 0.8697 - val_loss: 0.3424 - val_accuracy: 0.8683\n",
      "Epoch 2/10\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.3436 - accuracy: 0.8744 - val_loss: 0.4846 - val_accuracy: 0.8457\n",
      "Epoch 3/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.3449 - accuracy: 0.8763 - val_loss: 0.3150 - val_accuracy: 0.8745\n",
      "Epoch 4/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.3565 - accuracy: 0.8700 - val_loss: 0.3227 - val_accuracy: 0.8708\n",
      "Epoch 5/10\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.3391 - accuracy: 0.8766 - val_loss: 0.3229 - val_accuracy: 0.8657\n",
      "Epoch 6/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.3312 - accuracy: 0.8810 - val_loss: 0.3708 - val_accuracy: 0.8620\n",
      "Epoch 7/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.3383 - accuracy: 0.8731 - val_loss: 0.2983 - val_accuracy: 0.8871\n",
      "Epoch 8/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.3285 - accuracy: 0.8797 - val_loss: 0.3630 - val_accuracy: 0.8645\n",
      "Epoch 9/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.3342 - accuracy: 0.8807 - val_loss: 0.3158 - val_accuracy: 0.8833\n",
      "Epoch 10/10\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.3317 - accuracy: 0.8797 - val_loss: 0.3238 - val_accuracy: 0.8783\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.3238 - accuracy: 0.8783\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.3055 - accuracy: 0.8815\n",
      "Epoch 1/10\n",
      "64/64 [==============================] - 5s 31ms/step - loss: 0.3453 - accuracy: 0.8741 - val_loss: 0.3556 - val_accuracy: 0.8683\n",
      "Epoch 2/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.3318 - accuracy: 0.8810 - val_loss: 0.3027 - val_accuracy: 0.8908\n",
      "Epoch 3/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.3292 - accuracy: 0.8819 - val_loss: 0.3114 - val_accuracy: 0.8745\n",
      "Epoch 4/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.3276 - accuracy: 0.8785 - val_loss: 0.3047 - val_accuracy: 0.8846\n",
      "Epoch 5/10\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.3342 - accuracy: 0.8816 - val_loss: 0.3572 - val_accuracy: 0.8858\n",
      "Epoch 6/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.3260 - accuracy: 0.8816 - val_loss: 0.2993 - val_accuracy: 0.8846\n",
      "Epoch 7/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.3250 - accuracy: 0.8803 - val_loss: 0.3298 - val_accuracy: 0.8733\n",
      "Epoch 8/10\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.3313 - accuracy: 0.8825 - val_loss: 0.3024 - val_accuracy: 0.8858\n",
      "Epoch 9/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.3308 - accuracy: 0.8825 - val_loss: 0.3349 - val_accuracy: 0.8695\n",
      "Epoch 10/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.3259 - accuracy: 0.8841 - val_loss: 0.2936 - val_accuracy: 0.8896\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.2936 - accuracy: 0.8896\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.2922 - accuracy: 0.8855\n",
      "Epoch 1/10\n",
      "64/64 [==============================] - 5s 28ms/step - loss: 0.3455 - accuracy: 0.8734 - val_loss: 0.2897 - val_accuracy: 0.8883\n",
      "Epoch 2/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.3311 - accuracy: 0.8772 - val_loss: 0.3276 - val_accuracy: 0.8758\n",
      "Epoch 3/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.3243 - accuracy: 0.8822 - val_loss: 0.2928 - val_accuracy: 0.8896\n",
      "Epoch 4/10\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.3296 - accuracy: 0.8766 - val_loss: 0.3248 - val_accuracy: 0.8733\n",
      "Epoch 5/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.3229 - accuracy: 0.8838 - val_loss: 0.2888 - val_accuracy: 0.8921\n",
      "Epoch 6/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.3199 - accuracy: 0.8825 - val_loss: 0.3078 - val_accuracy: 0.8934\n",
      "Epoch 7/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.3217 - accuracy: 0.8816 - val_loss: 0.3168 - val_accuracy: 0.8795\n",
      "Epoch 8/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.3183 - accuracy: 0.8832 - val_loss: 0.2911 - val_accuracy: 0.8934\n",
      "Epoch 9/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.3207 - accuracy: 0.8838 - val_loss: 0.3466 - val_accuracy: 0.8695\n",
      "Epoch 10/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.3295 - accuracy: 0.8803 - val_loss: 0.3273 - val_accuracy: 0.8695\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.3273 - accuracy: 0.8695\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.3053 - accuracy: 0.8825\n",
      "Epoch 1/10\n",
      "64/64 [==============================] - 5s 29ms/step - loss: 0.3251 - accuracy: 0.8825 - val_loss: 0.3275 - val_accuracy: 0.8733\n",
      "Epoch 2/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.3174 - accuracy: 0.8879 - val_loss: 0.3615 - val_accuracy: 0.8607\n",
      "Epoch 3/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.3228 - accuracy: 0.8838 - val_loss: 0.3011 - val_accuracy: 0.8770\n",
      "Epoch 4/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.3214 - accuracy: 0.8872 - val_loss: 0.3192 - val_accuracy: 0.8758\n",
      "Epoch 5/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.3239 - accuracy: 0.8813 - val_loss: 1.8912 - val_accuracy: 0.3689\n",
      "Epoch 6/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.3541 - accuracy: 0.8706 - val_loss: 0.3049 - val_accuracy: 0.8833\n",
      "Epoch 7/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.3259 - accuracy: 0.8794 - val_loss: 0.3064 - val_accuracy: 0.8871\n",
      "Epoch 8/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.3238 - accuracy: 0.8838 - val_loss: 0.3943 - val_accuracy: 0.8444\n",
      "Epoch 9/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.3289 - accuracy: 0.8822 - val_loss: 0.3294 - val_accuracy: 0.8959\n",
      "Epoch 10/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.3199 - accuracy: 0.8835 - val_loss: 0.2866 - val_accuracy: 0.8934\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.2866 - accuracy: 0.8934\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.2895 - accuracy: 0.8886\n",
      "Epoch 1/10\n",
      "64/64 [==============================] - 5s 28ms/step - loss: 0.3435 - accuracy: 0.8737 - val_loss: 0.2984 - val_accuracy: 0.8896\n",
      "Epoch 2/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.3256 - accuracy: 0.8813 - val_loss: 0.3122 - val_accuracy: 0.8770\n",
      "Epoch 3/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.3194 - accuracy: 0.8885 - val_loss: 0.2957 - val_accuracy: 0.8934\n",
      "Epoch 4/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.3245 - accuracy: 0.8781 - val_loss: 0.2965 - val_accuracy: 0.8934\n",
      "Epoch 5/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.3196 - accuracy: 0.8844 - val_loss: 0.2902 - val_accuracy: 0.8934\n",
      "Epoch 6/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.3344 - accuracy: 0.8829 - val_loss: 0.3194 - val_accuracy: 0.8745\n",
      "Epoch 7/10\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.3240 - accuracy: 0.8769 - val_loss: 0.3265 - val_accuracy: 0.8733\n",
      "Epoch 8/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.3225 - accuracy: 0.8791 - val_loss: 0.2953 - val_accuracy: 0.8921\n",
      "Epoch 9/10\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.3090 - accuracy: 0.8829 - val_loss: 0.2925 - val_accuracy: 0.8934\n",
      "Epoch 10/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.3245 - accuracy: 0.8838 - val_loss: 0.3185 - val_accuracy: 0.8808\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.3185 - accuracy: 0.8808\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.3097 - accuracy: 0.8876\n",
      "Epoch 1/10\n",
      "64/64 [==============================] - 5s 29ms/step - loss: 0.3199 - accuracy: 0.8803 - val_loss: 0.3070 - val_accuracy: 0.8896\n",
      "Epoch 2/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.3241 - accuracy: 0.8844 - val_loss: 0.3952 - val_accuracy: 0.8381\n",
      "Epoch 3/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.3185 - accuracy: 0.8816 - val_loss: 0.3117 - val_accuracy: 0.8795\n",
      "Epoch 4/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.3206 - accuracy: 0.8860 - val_loss: 0.4556 - val_accuracy: 0.8243\n",
      "Epoch 5/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.3281 - accuracy: 0.8851 - val_loss: 0.3269 - val_accuracy: 0.8783\n",
      "Epoch 6/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.3742 - accuracy: 0.8665 - val_loss: 0.3988 - val_accuracy: 0.8846\n",
      "Epoch 7/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.3559 - accuracy: 0.8747 - val_loss: 0.3131 - val_accuracy: 0.8670\n",
      "Epoch 8/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.3838 - accuracy: 0.8659 - val_loss: 0.3747 - val_accuracy: 0.8407\n",
      "Epoch 9/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.3413 - accuracy: 0.8734 - val_loss: 0.3570 - val_accuracy: 0.8507\n",
      "Epoch 10/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.3531 - accuracy: 0.8653 - val_loss: 0.3899 - val_accuracy: 0.8356\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.3899 - accuracy: 0.8356\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.3524 - accuracy: 0.8645\n",
      "Epoch 1/10\n",
      "64/64 [==============================] - 5s 28ms/step - loss: 0.3527 - accuracy: 0.8719 - val_loss: 0.3201 - val_accuracy: 0.8570\n",
      "Epoch 2/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.3330 - accuracy: 0.8753 - val_loss: 0.3068 - val_accuracy: 0.8808\n",
      "Epoch 3/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.3213 - accuracy: 0.8813 - val_loss: 0.3506 - val_accuracy: 0.8632\n",
      "Epoch 4/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.3211 - accuracy: 0.8819 - val_loss: 0.3017 - val_accuracy: 0.8871\n",
      "Epoch 5/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.3236 - accuracy: 0.8810 - val_loss: 0.3109 - val_accuracy: 0.8858\n",
      "Epoch 6/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.3128 - accuracy: 0.8854 - val_loss: 0.3326 - val_accuracy: 0.8745\n",
      "Epoch 7/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.3128 - accuracy: 0.8832 - val_loss: 0.3508 - val_accuracy: 0.8908\n",
      "Epoch 8/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.3777 - accuracy: 0.8634 - val_loss: 0.3357 - val_accuracy: 0.8795\n",
      "Epoch 9/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.3179 - accuracy: 0.8851 - val_loss: 0.3786 - val_accuracy: 0.8494\n",
      "Epoch 10/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.3221 - accuracy: 0.8778 - val_loss: 0.3036 - val_accuracy: 0.8908\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.3036 - accuracy: 0.8908\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.3024 - accuracy: 0.8855\n",
      "[[0.3717900514602661, 0.8627512454986572, 0.34922754764556885, 0.8644918203353882, 0.34922757744789124, 0.8644918203353882, 0.33291342854499817, 0.33291342854499817], [0.3531149923801422, 0.8693467378616333, 0.3281839191913605, 0.8820577263832092, 0.3281839191913605, 0.8820577263832092, 0.3374943435192108, 0.3374943435192108], [0.34099793434143066, 0.8759422302246094, 0.3693449795246124, 0.8582183122634888, 0.3693449795246124, 0.8582183122634888, 0.32513633370399475, 0.32513633370399475], [0.33174195885658264, 0.8797110319137573, 0.3238334059715271, 0.8782935738563538, 0.3238334059715271, 0.8782935738563538, 0.30551499128341675, 0.30551499128341675], [0.3259398937225342, 0.8841080665588379, 0.29363223910331726, 0.8895859718322754, 0.2936321794986725, 0.8895859718322754, 0.2922486960887909, 0.2922486960887909], [0.32949039340019226, 0.8803392052650452, 0.3272598683834076, 0.8695106506347656, 0.32725989818573, 0.8695106506347656, 0.3053331971168518, 0.3053331971168518], [0.3199313282966614, 0.88347989320755, 0.28661853075027466, 0.8933500647544861, 0.28661856055259705, 0.8933500647544861, 0.2895076274871826, 0.2895076274871826], [0.3244647979736328, 0.8837939500808716, 0.31845977902412415, 0.8808029890060425, 0.31845980882644653, 0.8808029890060425, 0.3097262680530548, 0.3097262680530548], [0.35309672355651855, 0.865263819694519, 0.3898946940898895, 0.8356336355209351, 0.3898947238922119, 0.8356336355209351, 0.35239601135253906, 0.35239601135253906], [0.3221339285373688, 0.8778266310691833, 0.30363214015960693, 0.8908406496047974, 0.30363214015960693, 0.8908406496047974, 0.30238640308380127, 0.30238640308380127]]\n"
     ]
    }
   ],
   "source": [
    "repeats = []\n",
    "\n",
    "for i in range(10):\n",
    "    train_input, test_input, train_target, test_target = train_test_split(data, target, test_size=0.2, stratify=target, random_state=0)\n",
    "    train_input, val_input, train_target, val_target = train_test_split(train_input, train_target, test_size=0.2, stratify=train_target, random_state=0)\n",
    "\n",
    "    model.compile(optimizer='rmsprop', \n",
    "                loss='binary_crossentropy', \n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    checkpoint_cb = keras.callbacks.ModelCheckpoint('test.h5')\n",
    "    early_stopping_cb = keras.callbacks.EarlyStopping(patience = 15, restore_best_weights=True)\n",
    "\n",
    "    history = model.fit(train_input, train_target, \n",
    "                        epochs=10, batch_size = 50,\n",
    "                        validation_data = (val_input, val_target),\n",
    "                        callbacks=[checkpoint_cb, early_stopping_cb])\n",
    "\n",
    "    val_evaluate = model.evaluate(val_input, val_target)\n",
    "    test_evaluate = model.evaluate(test_input, test_target)\n",
    "    \n",
    "    repeat = []\n",
    "    repeat.append(history.history['loss'][-1])\n",
    "    repeat.append(history.history['accuracy'][-1])\n",
    "    repeat.append(history.history['val_loss'][-1])\n",
    "    repeat.append(history.history['val_accuracy'][-1])\n",
    "    repeat.append(val_evaluate[0])\n",
    "    repeat.append(val_evaluate[1])\n",
    "    repeat.append(test_evaluate[0])\n",
    "    repeat.append(test_evaluate[0])\n",
    "    repeats.append(repeat)\n",
    "\n",
    "\n",
    "print(repeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_eval_loss</th>\n",
       "      <th>val_eval_acc</th>\n",
       "      <th>test_eval_loss</th>\n",
       "      <th>test_eval_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.371790</td>\n",
       "      <td>0.862751</td>\n",
       "      <td>0.349228</td>\n",
       "      <td>0.864492</td>\n",
       "      <td>0.349228</td>\n",
       "      <td>0.864492</td>\n",
       "      <td>0.332913</td>\n",
       "      <td>0.332913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.353115</td>\n",
       "      <td>0.869347</td>\n",
       "      <td>0.328184</td>\n",
       "      <td>0.882058</td>\n",
       "      <td>0.328184</td>\n",
       "      <td>0.882058</td>\n",
       "      <td>0.337494</td>\n",
       "      <td>0.337494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.340998</td>\n",
       "      <td>0.875942</td>\n",
       "      <td>0.369345</td>\n",
       "      <td>0.858218</td>\n",
       "      <td>0.369345</td>\n",
       "      <td>0.858218</td>\n",
       "      <td>0.325136</td>\n",
       "      <td>0.325136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.331742</td>\n",
       "      <td>0.879711</td>\n",
       "      <td>0.323833</td>\n",
       "      <td>0.878294</td>\n",
       "      <td>0.323833</td>\n",
       "      <td>0.878294</td>\n",
       "      <td>0.305515</td>\n",
       "      <td>0.305515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.325940</td>\n",
       "      <td>0.884108</td>\n",
       "      <td>0.293632</td>\n",
       "      <td>0.889586</td>\n",
       "      <td>0.293632</td>\n",
       "      <td>0.889586</td>\n",
       "      <td>0.292249</td>\n",
       "      <td>0.292249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.329490</td>\n",
       "      <td>0.880339</td>\n",
       "      <td>0.327260</td>\n",
       "      <td>0.869511</td>\n",
       "      <td>0.327260</td>\n",
       "      <td>0.869511</td>\n",
       "      <td>0.305333</td>\n",
       "      <td>0.305333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.319931</td>\n",
       "      <td>0.883480</td>\n",
       "      <td>0.286619</td>\n",
       "      <td>0.893350</td>\n",
       "      <td>0.286619</td>\n",
       "      <td>0.893350</td>\n",
       "      <td>0.289508</td>\n",
       "      <td>0.289508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.324465</td>\n",
       "      <td>0.883794</td>\n",
       "      <td>0.318460</td>\n",
       "      <td>0.880803</td>\n",
       "      <td>0.318460</td>\n",
       "      <td>0.880803</td>\n",
       "      <td>0.309726</td>\n",
       "      <td>0.309726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.353097</td>\n",
       "      <td>0.865264</td>\n",
       "      <td>0.389895</td>\n",
       "      <td>0.835634</td>\n",
       "      <td>0.389895</td>\n",
       "      <td>0.835634</td>\n",
       "      <td>0.352396</td>\n",
       "      <td>0.352396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.322134</td>\n",
       "      <td>0.877827</td>\n",
       "      <td>0.303632</td>\n",
       "      <td>0.890841</td>\n",
       "      <td>0.303632</td>\n",
       "      <td>0.890841</td>\n",
       "      <td>0.302386</td>\n",
       "      <td>0.302386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss       acc  val_loss   val_acc  val_eval_loss  val_eval_acc  \\\n",
       "0  0.371790  0.862751  0.349228  0.864492       0.349228      0.864492   \n",
       "1  0.353115  0.869347  0.328184  0.882058       0.328184      0.882058   \n",
       "2  0.340998  0.875942  0.369345  0.858218       0.369345      0.858218   \n",
       "3  0.331742  0.879711  0.323833  0.878294       0.323833      0.878294   \n",
       "4  0.325940  0.884108  0.293632  0.889586       0.293632      0.889586   \n",
       "5  0.329490  0.880339  0.327260  0.869511       0.327260      0.869511   \n",
       "6  0.319931  0.883480  0.286619  0.893350       0.286619      0.893350   \n",
       "7  0.324465  0.883794  0.318460  0.880803       0.318460      0.880803   \n",
       "8  0.353097  0.865264  0.389895  0.835634       0.389895      0.835634   \n",
       "9  0.322134  0.877827  0.303632  0.890841       0.303632      0.890841   \n",
       "\n",
       "   test_eval_loss  test_eval_acc  \n",
       "0        0.332913       0.332913  \n",
       "1        0.337494       0.337494  \n",
       "2        0.325136       0.325136  \n",
       "3        0.305515       0.305515  \n",
       "4        0.292249       0.292249  \n",
       "5        0.305333       0.305333  \n",
       "6        0.289508       0.289508  \n",
       "7        0.309726       0.309726  \n",
       "8        0.352396       0.352396  \n",
       "9        0.302386       0.302386  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_name = ['loss', 'acc', 'val_loss', 'val_acc', 'val_eval_loss', 'val_eval_acc', 'test_eval_loss', 'test_eval_acc']\n",
    "\n",
    "result = pd.DataFrame(repeats, columns = col_name)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0e56d166fbc896341d80a58b1f49edfebe20bc75f207edfdf6ccda3bd4653dde"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('Senior_Fall_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
